{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPpYUccj5F4p4Ujey3pkh+E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dennistay1981/Resources/blob/main/Code%20and%20data%20in%20publications/Chapter%3A%20Machine%20learning%20and%20healthcare%20discourse%20research%3A%20sample%20applications/Machine_learning_and_healthcare_discourse_research.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Supervised learning example: survival regression of metaphors"
      ],
      "metadata": {
        "id": "iBMtqDOz2zfT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import Python libraries\n",
        "!pip install lifelines\n",
        "from lifelines import KaplanMeierFitter\n",
        "from lifelines import CoxPHFitter\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Import data\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/dennistay1981/Resources/refs/heads/main/Code%20and%20data%20in%20publications/Chapter%3A%20Machine%20learning%20and%20healthcare%20discourse%20research%3A%20sample%20applications/Survival.csv')\n"
      ],
      "metadata": {
        "id": "gQ8PVPohD5u8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Cumulative distribution function (CDF) of survived turns by Initiator and Approach\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
        "\n",
        "sns.ecdfplot(df, x='Turns', hue='Initiator', ax=axes[0])\n",
        "axes[0].set_title('CDF by INITIATOR')\n",
        "\n",
        "sns.ecdfplot(df, x='Turns', hue='Approach', ax=axes[1])\n",
        "axes[1].set_title('CDF by APPROACH')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oSOcdLdlVmOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bc461228"
      },
      "source": [
        "\"\"\"\n",
        "Combined Figure 1\n",
        "\"\"\"\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5)) # Create a figure with 2 subplots\n",
        "\n",
        "# Plot survival function by INITIATOR on the first subplot\n",
        "kmf_A = KaplanMeierFitter()\n",
        "ax = kmf_A.fit(durations=df.loc[df.Initiator =='T'].Turns,\n",
        "               event_observed=df.loc[df.Initiator =='T'].Attrition, label='Therapist').plot_survival_function(ax=axes[0])\n",
        "axes[0].hlines(0.5, 0, kmf_A.median_survival_time_ , linestyle='--', color='black')\n",
        "axes[0].vlines(kmf_A.median_survival_time_ , 0, 0.5, linestyle='--', color='black')\n",
        "\n",
        "kmf_B = KaplanMeierFitter()\n",
        "ax = kmf_B.fit(durations=df.loc[df.Initiator =='C'].Turns,\n",
        "               event_observed=df.loc[df.Initiator =='C'].Attrition, label='Client').plot_survival_function(ax=axes[0])\n",
        "axes[0].hlines(0.5, 0, kmf_B.median_survival_time_ , linestyle='--', color='black')\n",
        "axes[0].vlines(kmf_B.median_survival_time_, 0, 0.5, linestyle='--', color='black')\n",
        "\n",
        "axes[0].legend()\n",
        "axes[0].set_ylabel('Probability')\n",
        "axes[0].set_xlabel('Timeline (turns)')\n",
        "axes[0].set_xticks(range(0, 24))\n",
        "axes[0].set_title('Survival curve by INITIATOR')\n",
        "axes[0].set_xlim(0, axes[0].get_xlim()[1])\n",
        "axes[0].set_ylim(0, axes[0].get_ylim()[1])\n",
        "\n",
        "# Plot survival function by APPROACH on the second subplot\n",
        "kmf_A = KaplanMeierFitter()\n",
        "ax = kmf_A.fit(durations=df.loc[df.Approach =='CBT'].Turns,\n",
        "               event_observed=df.loc[df.Approach =='CBT'].Attrition, label='CBT').plot_survival_function(ax=axes[1])\n",
        "axes[1].hlines(0.5, 0, kmf_A.median_survival_time_ , linestyle='--', color='black')\n",
        "axes[1].vlines(kmf_A.median_survival_time_ , 0, 0.5, linestyle='--', color='black')\n",
        "\n",
        "kmf_B = KaplanMeierFitter()\n",
        "ax = kmf_B.fit(durations=df.loc[df.Approach =='PA'].Turns,\n",
        "               event_observed=df.loc[df.Approach =='PA'].Attrition, label='PA').plot_survival_function(ax=axes[1])\n",
        "axes[1].hlines(0.5, 0, kmf_B.median_survival_time_ , linestyle='--', color='black')\n",
        "axes[1].vlines(kmf_B.median_survival_time_ , 0, 0.5, linestyle='--', color='black')\n",
        "\n",
        "\n",
        "axes[1].legend()\n",
        "axes[1].set_ylabel('Probability')\n",
        "axes[1].set_xlabel('Timeline (turns)')\n",
        "axes[1].set_xticks(range(0, 24))\n",
        "axes[1].set_title('Survival curve by APPROACH')\n",
        "axes[1].set_xlim(0, axes[1].get_xlim()[1])\n",
        "axes[1].set_ylim(0, axes[1].get_ylim()[1])\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Fit Coxâ€™s Proportional Hazards regression model\n",
        "\"\"\"\n",
        "coxph = CoxPHFitter()\n",
        "coxph.fit(df, duration_col='Turns', event_col='Attrition', formula=\"Initiator+Approach\") #can also add cluster_col='XX' to account for clustered subjects (like 'random effects')\n",
        "coxph.print_summary()\n"
      ],
      "metadata": {
        "id": "2S0QrTmQEBri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Unsupervised learning example: clusters as emergent synchrony measures"
      ],
      "metadata": {
        "id": "XNU9fp1v6Qg8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import Python libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import scipy.cluster.hierarchy as shc\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy.cluster.hierarchy import linkage, dendrogram, cophenet\n",
        "from scipy.spatial.distance import pdist\n",
        "from sklearn.cluster import KMeans"
      ],
      "metadata": {
        "id": "TejUITCG6Uu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Import Psychoanalysis dataset\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/dennistay1981/Resources/refs/heads/main/Code%20and%20data%20in%20publications/Chapter%3A%20Machine%20learning%20and%20healthcare%20discourse%20research%3A%20sample%20applications/Psychoanalysis.csv', index_col='Session')\n",
        "\n",
        "#scale features for better clustering outcomes\n",
        "scaler=StandardScaler()\n",
        "scaler.fit(df)\n",
        "df=pd.DataFrame(scaler.transform(df),columns=df.columns,index=df.index)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "K-means clustering\n",
        "\"\"\"\n",
        "#determine the optimal number of clusters with silhouette scores\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "num_clusters = np.arange(2, 11)\n",
        "silhouette_scores = []\n",
        "\n",
        "for i in num_clusters:\n",
        "    # Iterate over each k, train model, and calculate silhouette score\n",
        "    model = KMeans(n_clusters=i)\n",
        "    labels = model.fit_predict(df)\n",
        "    silhouette_scores.append(silhouette_score(df, labels))\n",
        "\n",
        "#generate silhouette plot\n",
        "plt.plot(num_clusters,  silhouette_scores, '-o')\n",
        "plt.xlabel('number of clusters, k')\n",
        "plt.ylabel('silhouette scores')\n",
        "plt.title('Silhouette plot')\n",
        "plt.xticks(num_clusters)\n",
        "plt.show()\n",
        "\n",
        "#generate cluster centroids and labels using the optimal number of clusters (3 for psychoanalysis, 2 for CBT)\n",
        "model = KMeans(n_clusters=3)\n",
        "labels = model.fit_predict(df)\n",
        "\n",
        "#obtain cluster centroid positions for later plotting\n",
        "cluster_centres = model.cluster_centers_\n",
        "\n",
        "\"\"\"\n",
        "Generate 2D-scatterplot to visualize clustering solution\n",
        "\"\"\"\n",
        "from sklearn.decomposition import PCA as sklearnPCA\n",
        "#specify two principal components\n",
        "pca = sklearnPCA(n_components=2)\n",
        "#reduce the cluster centroid locations into two dimensions\n",
        "cent=pca.fit_transform(cluster_centres).T\n",
        "#use data.iloc to remove cluster labels in the rightmost column before reducing the data\n",
        "reduced=pd.DataFrame(pca.fit_transform(df),columns=['Dim_1','Dim_2'],index=df.index)\n",
        "\n",
        "#generate scatterplot and color according to clusters\n",
        "sns.scatterplot(x='Dim_1', y='Dim_2', hue=labels, data=reduced, palette='tab10', s=30)\n",
        "#plot cluster centroids\n",
        "plt.plot(cent[0],cent[1],'rx',markersize=15)\n",
        "#annotate each object\n",
        "for i in range(reduced.shape[0]):\n",
        "    plt.text(x=reduced.Dim_1[i]+0.05, y=reduced.Dim_2[i]+0.05, s=reduced.index[i],\n",
        "             fontdict=dict(color='black',size=8))\n",
        "plt.legend(title='cluster')\n",
        "plt.xlabel(\"Dimension 1\")\n",
        "plt.ylabel(\"Dimension 2\")\n",
        "plt.title(\"Psychoanalysis dyad\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "hHOyEmZaEIHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Repeat the above for CBT dataset\n",
        "\"\"\"\n",
        "#Import CBT dataset\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/dennistay1981/Resources/refs/heads/main/Code%20and%20data%20in%20publications/Chapter%3A%20Machine%20learning%20and%20healthcare%20discourse%20research%3A%20sample%20applications/CBT.csv', index_col='Session' )\n",
        "\n",
        "#scale features for better clustering outcomes\n",
        "scaler=StandardScaler()\n",
        "scaler.fit(df)\n",
        "df=pd.DataFrame(scaler.transform(df),columns=df.columns,index=df.index)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "K-means clustering\n",
        "\"\"\"\n",
        "#determine the optimal number of clusters with silhouette scores\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "num_clusters = np.arange(2, 11)\n",
        "silhouette_scores = []\n",
        "\n",
        "for i in num_clusters:\n",
        "    # Iterate over each k, train model, and calculate silhouette score\n",
        "    model = KMeans(n_clusters=i)\n",
        "    labels = model.fit_predict(df)\n",
        "    silhouette_scores.append(silhouette_score(df, labels))\n",
        "\n",
        "#generate silhouette plot\n",
        "plt.plot(num_clusters,  silhouette_scores, '-o')\n",
        "plt.xlabel('number of clusters, k')\n",
        "plt.ylabel('silhouette scores')\n",
        "plt.title('Silhouette plot')\n",
        "plt.xticks(num_clusters)\n",
        "plt.show()\n",
        "\n",
        "#generate cluster centroids and labels using the optimal number of clusters (3 for psychoanalysis, 2 for CBT)\n",
        "model = KMeans(n_clusters=2)\n",
        "labels = model.fit_predict(df)\n",
        "\n",
        "#obtain cluster centroid positions for later plotting\n",
        "cluster_centres = model.cluster_centers_\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Generate 2D-scatterplot to visualize clustering solution\n",
        "\"\"\"\n",
        "from sklearn.decomposition import PCA as sklearnPCA\n",
        "#specify two principal components\n",
        "pca = sklearnPCA(n_components=2)\n",
        "#reduce the cluster centroid locations into two dimensions\n",
        "cent=pca.fit_transform(cluster_centres).T\n",
        "#use data.iloc to remove cluster labels in the rightmost column before reducing the data\n",
        "reduced=pd.DataFrame(pca.fit_transform(df),columns=['Dim_1','Dim_2'],index=df.index)\n",
        "\n",
        "#generate scatterplot and color according to clusters\n",
        "sns.scatterplot(x='Dim_1', y='Dim_2', hue=labels, data=reduced, palette='tab10', s=30)\n",
        "#plot cluster centroids\n",
        "plt.plot(cent[0],cent[1],'rx',markersize=15)\n",
        "#annotate each object\n",
        "for i in range(reduced.shape[0]):\n",
        "    plt.text(x=reduced.Dim_1[i]+0.05, y=reduced.Dim_2[i]+0.05, s=reduced.index[i],\n",
        "             fontdict=dict(color='black',size=8))\n",
        "plt.legend(title='cluster')\n",
        "plt.xlabel(\"Dimension 1\")\n",
        "plt.ylabel(\"Dimension 2\")\n",
        "plt.title(\"CBT dyad\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Plot cluster centroids in terms of LIWC scores\n",
        "\"\"\"\n",
        "pd.DataFrame(cluster_centres, columns=df.columns).plot(kind='bar')\n",
        "plt.title(\"Cluster centroids (CBT dyad)\")\n"
      ],
      "metadata": {
        "id": "-z_mOXXLESmT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}